---
layout: post
title: "[GAN] pix2pix"
date: 2022-04-05 08:44:38 -0400
category: deep-learning
author: eun
short-description: C
toc: true
use_math: true

---

#### pix2pix
---

<p align="center"><img src="/assets/images/pix2pix.png"  width="60%" height="60%"></p>

Pix2PixëŠ” ì´ë¯¸ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ë„ë¡ genertorë¥¼ í•™ìŠµí•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, generatorì˜ ì…ë ¥ê°’ìœ¼ë¡œ ìŠ¤ì¼€ì¹˜ ê·¸ë¦¼ì„ ì…ë ¥í•˜ë©´ ì™„ì„±ëœ ê·¸ë¦¼ì´ ë‚˜ì˜¤ë„ë¡ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. ê¸°ì¡´ GANê³¼ ë¹„êµí•˜ì—¬ ì„¤ëª…í•˜ìë©´, **pix2pix**ëŠ” ê¸°ì¡´ GANì˜ noise ëŒ€ì‹  ìŠ¤ì¼€ì¹˜ ê·¸ë¦¼ì„ ì…ë ¥í•˜ì—¬ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤. 

- generator: ìŠ¤ì¼€ì¹˜ë¥¼ ì…ë ¥ë°›ì•„ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥
- discriminator: ìƒì„±ê¸°ê°€ ìƒì„±í•œ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ì™„ì„±ëœ ê·¸ë¦¼ìœ¼ë¡œ ì‹ë³„í•˜ë„ë¡ ëª©ì  í•¨ìˆ˜ë¥¼ ì„¤ê³„í•˜ì—¬ í•™ìŠµì„ ì§„í–‰í•œë‹¤. 

í•™ìŠµì„ í†µí•´ generatorì€ ì ì°¨ì ìœ¼ë¡œ ì™„ì„±ëœ ê°€ì§œ ê·¸ë¦¼ì„ ì¶œë ¥í•œë‹¤. 

<p style="font-size: 1.12em">ğŸ“Œpix2pix ëª©í‘œ</p>
---



$G, D$ë¥¼ ê°ê° ìƒì„± ëª¨ë¸ê³¼ íŒë³„ ëª¨ë¸ì´ë¼ í•˜ì. $x, y, z$ë¥¼ ê°ê° ì…ë ¥ ì´ë¯¸ì§€, ì¶œë ¥ ì´ë¯¸ì§€, ë…¸ì´ì¦ˆë¼ê³  í•˜ì.

<!-- cGANì˜ ëª©í‘œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ ë˜ëŠ” c -->


<p style="font-size: 1.12em">ğŸ“ŒGenerator</p>

<p align="center"><img src="/assets/images/pix2pix_01.PNG"  width="60%" height="60%"></p>

Generatorì€ ì™¼ìª½ê³¼ ê°™ì€ Inputì„ ë°›ì•„ ì˜¤ë¥¸ìª½ê³¼ ê°™ì€ ì¶œë ¥ê°’ì„ ìƒì„±í•˜ë©° Discriminatorì„ ì†ì´ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•œë‹¤. 

L1 ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ìƒì„±ê¸°ê°€ blurê°€ ì ìš©ëœ row-frequency(ì €í•´ìƒë„) ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤. ìœ„ ê·¸ë¦¼ ì† L1ë§Œ ì‚¬ìš©í•œ ê·¸ë¦¼ì„ ë³´ë©´ ë§¤ìš° íë¦¿í•œ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. ê¸°ì¡´ì˜ gan ì†ì‹¤ í•¨ìˆ˜ì— L1 ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì¶”ê°€í•˜ë©´ high-frequency(ê³ í•´ìƒë„) ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤. 

```python
class Generator(object):
    def __init__(self, width = 28, height= 28, channels = 1):
        
        self.W = width
        self.H = height
        self.C = channels
        self.SHAPE = (width,height,channels)

        self.Generator = self.model()
        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)
        self.Generator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER,metrics=['accuracy'])

        self.summary()


    # ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±
    def model(self):
        input_layer = Input(shape=self.SHAPE)
        
        down_1 = Convolution2D(64  , kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)
        norm_1 = InstanceNormalization()(down_1)

        down_2 = Convolution2D(64*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_1)
        norm_2 = InstanceNormalization()(down_2)

        down_3 = Convolution2D(64*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_2)
        norm_3 = InstanceNormalization()(down_3)

        down_4 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_3)
        norm_4 = InstanceNormalization()(down_4)


        upsample_1 = UpSampling2D()(norm_4)
        up_conv_1 = Convolution2D(64*4, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_1)
        norm_up_1 = InstanceNormalization()(up_conv_1)
        add_skip_1 = Concatenate()([norm_up_1,norm_3])

        upsample_2 = UpSampling2D()(add_skip_1)
        up_conv_2 = Convolution2D(64*2, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_2)
        norm_up_2 = InstanceNormalization()(up_conv_2)
        add_skip_2 = Concatenate()([norm_up_2,norm_2])

        upsample_3 = UpSampling2D()(add_skip_2)
        up_conv_3 = Convolution2D(64, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_3)
        norm_up_3 = InstanceNormalization()(up_conv_3)
        add_skip_3 = Concatenate()([norm_up_3,norm_1])

        last_upsample = UpSampling2D()(add_skip_3)
        output_layer = Convolution2D(3, kernel_size=4, strides=1, padding='same',activation='tanh')(last_upsample)
        
        return Model(input_layer,output_layer)
```

<p style="font-size: 1.12em">ğŸ“ŒDiscriminator</p>

pix2pixëŠ” íŒë³„ê¸°ë¥¼ patch ganì„ ì‚¬ìš©í•œë‹¤. 

- patch gan: ì¶œë ¥ê°’ìœ¼ë¡œ í•˜ë‚˜ì˜ scalar ê°’ì„ ì¶œë ¥í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì´ë¯¸ì§€ë¥¼ ë¶„í• í•œ í”¼ì²˜ë§µì„ ì¶œë ¥í•œë‹¤. 
    + 256X256 í¬ê¸°ì˜ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ ë°›ì€ ê²½ìš°, 30X30ì˜ ì¶œë ¥ê°’ì„ ìƒì„±í•¨
    + ì›ë˜ ì´ë¯¸ì§€ê°€ 30X30 feature mapìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° pixelì„ real, fakeì¸ì§€ ì‹ë³„í•˜ëŠ” ê²ƒì´ë‹¤.
    + ì¡°ê±´ë¶€ ganì´ê¸° ë•Œë¬¸ì—, ì¡°ê±´ë¶€ ë°ì´í„°ë¥¼ ì…ë ¥ë°›ëŠ”ë‹¤. ì•„ë˜ ê·¸ë¦¼ ë‘ê°œë¥¼ í•œêº¼ë²ˆì— ì…ë ¥ë°›ìŒ
    + <p><img src="/assets/images/pix2pix_02.png"  width="30%" height="30%"></p>

```python
class Discriminator(object):
    def __init__(self, width = 28, height= 28, channels = 1):
        self.W = width
        self.H = height
        self.C = channels
        self.CAPACITY = width*height*channels
        self.SHAPE = (width,height,channels)
        
        self.Discriminator = self.model()
        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)
        self.Discriminator.compile(loss='mse', optimizer=self.OPTIMIZER, metrics=['accuracy'] )

        self.summary()

    # ê°€ì§œ ì´ë¯¸ì§€ íŒë³„: patch ganì„ ì‚¬ìš©
    # patch gan: ì´ë¯¸ì§€ë¥¼ 
    def model(self):
        input_layer = Input(self.SHAPE)

        up_layer_1 = Convolution2D(64, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)

        up_layer_2 = Convolution2D(64*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(up_layer_1)
        norm_layer_1 = InstanceNormalization()(up_layer_2)

        up_layer_3 = Convolution2D(64*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_layer_1)
        norm_layer_2 = InstanceNormalization()(up_layer_3)

        up_layer_4 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_layer_2)
        norm_layer_3 =InstanceNormalization()(up_layer_4)

        output_layer = Convolution2D(1, kernel_size=4, strides=1, padding='same')(norm_layer_3)
        output_layer_1 = Flatten()(output_layer)
        output_layer_2 = Dense(1, activation='sigmoid')(output_layer_1)
        
        return Model(input_layer,output_layer_2)
```

patch ganì„ ì‚¬ìš©í•˜ë©´ high-frequencyì˜ ì •í™•ë„ê°€ ë†’ì•„ì§„ë‹¤
+ high-frequency: ê³ í•´ìƒë„
+ high-frequencyì˜ ì •í™•ë„ê°€ ë†’ì•„ì§„ë‹¤: ë””í…Œì¼í•œ ë¶€ë¶„ì´ í–¥ìƒëœë‹¤.


---
<p style="font-size: 1.0em">References</p>

<a href = "https://github.com/wikibook/gan" style="font-size: 0.8em"> ì‹¤ì „ ì˜ˆì œë¡œ ë°°ìš°ëŠ” GAN(ìœ„í‚¤ë¶ìŠ¤) </a>      
<a href = "https://arxiv.org/pdf/1611.07004.pdf" style="font-size: 0.8em"> Image-to-Image Translation with Conditional Adversarial Networks </a>      
