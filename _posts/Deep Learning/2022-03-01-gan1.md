---
layout: post
title: "[GAN] What Is a Generative Adversarial Network? - 1"
date: 2022-03-13 08:44:38 -0400
category: deep-learning
author: eun
short-description: 생성적 적대 신경망이란?
toc: true
---

#### intro
---
생성적 적대(Generative Adversarial Network, GAN)은 오늘날 딥러닝 분야에서 중요한 연구 주제이다. 이 아키텍처를 사용하면 일반적인 방식으로는 학습하게 하기 힘든 생성 모델까지 제작해 낼 수 있기 때문이다. 이 아키텍처를 사용하면 얻게 되는 이점은 여러가지이다.
- 데이터가 한정된 상황에서 **일반화**`Generalization` 가능
- 작은 데이터셋을 가지고 새로운 장면을 만들 수 있음
- **모조 데이터**`simulated data`를 더욱 진짜처럼 보이게 할 수 있음
- 작은 데이터만 가지고 다양한 일을 할 수 있다는 장점이 있다. 
    + 오늘날에 사용되는 다양한 기술을 구현하려면 상당히 많은 데이터가 필요하다.
    + 여러 가지 과업들을 완성하는 데 필요한 데이터 분량을 축소할 수 있음
    + 다른 아키텍처을 사용해 딥러닝 문제를 풀 떄에 비해 10%의 데이터만 있어도 문제를 풀 수 있음

<br>

#### generative modeling & discriminative modeling
---

- **GAN: 적대적 생성모델**
- **두 개 이상의 신경망이 서로를 향하게 하고, 서로 대항하듯이 훈련하게 함으로써, 결과적으로 생성 모델을 산출해낸다.**

머신러닝과 딥러닝은 **생성 모델링(`generative modeling`)** 및 **판별 모델링(`discriminative modeling`)**이라는 두 가지 용어로 설명할 수 있다. 머신러닝의 **분류(`classifaction`)** 기법은 전형적인 판별 모델링 기술에 해당한다.

<p align="center"><img src="/assets/images/gan3.png" width="70%" height="70%"></p>

<p style="font-size: 1.12em">📌 판별 모델링</p>
- **판별 모델**: 실제 데이터와 생성 모델이 생성한 가짜 데이터를 구별하도록 학습
- 예) 그림을 살펴본 다음 해당 그림의 화풍`style`을 정하는 일은 무엇인가 판단하는 일
- 판별 모델링 수행 방식
1. 데이터 내의 각 부분을 이해하기 위해 합성곱 계층을 만들거나, 기타 학습된 특징들을 사용하는 머신러닝 모델을 만든다.
2. 훈련 집합(전체 데이터 중 60~90%)과 검증 집합(전체 데이터 중 10~40%)이 모두 포함된 데이터셋을 수집한다
3. 전체 데이터를 사용해 머신러닝 모델을 훈련한다
4. 머신러닝 모델을 사용해 **데이터가 어떤 특정 계급`(classes`)에 속하는지** 예측한다. 
- 판별 모델의 작동 방식
    + **분포(`distributions`)**에 대한 계급 간의 **경계 조건(`boundary conditions`)**을 학습
    + 데이터가 많을 수록 판별 모델의 성능이 좋아진다
    + 비지도 방식 X: 레이블`label`이 지정되지 않은 데이터 사용 가능 X
    + 결정 경계만 학습하면 된다
<p align="center"><img src="/assets/images/gan13.png" width="30%" height="30%"></p>


<p style="font-size: 1.12em">📌 생성 모델링</p>
- **생성 모델**: 생성된 데이터를 받아, 실제 데이터와 비슷한 가짜 데이터를 만들어내도록 학습
- 예) 화풍에 대한 지식을 쌓고, 다양한 화가의 화풍에 따라 그림을 재현하는 것
- 생성 모델링 수행 방식
1. 다양한 그림의 화풍을 **복제(`reproduce`)**하는 방법을 학습하는 머신러닝 모델 작성한다.
2. 훈련 데이터셋과 검증 데이터셋 수집한다.
3. 수집한 데이터를 사용해 머신러닝 모델을 훈련한다.
4. 머신러닝 모델을 사용해 그림 작가가 그린**사례(`examples`)**를 바탕으로 예측한다.  즉, **유사도(`similarity`)**라고 하는 **계랑기준(`metrics`)**을 사용해 모델에서 화풍을 재현하는 기능을 확인한다.
- 생성 모델의 작동 방식
    + 주어진 입력의 분포에 대한 계급들의 분포를 모델링한다
    + 분포를 추정하기 위해 각 계급에 대한 확률 모델을 만든다
    + 레이블 없는 데이터 사용 가능: 훈련을 하는 중 알아서 레이블 학습
    + 입력 분포를 정확하게 모델링하고 복제해야 하므로, 한계 이상의 무언가를 새로 산출해 내기가 어렵다.
<p align="center"><img src="/assets/images/gan14.png" width="30%" height="30%"></p>

<br>

#### GAN의 구조 
---
GAN이라는 신경망 아키텍처를 구성하려면 몇 가지 주요 구성 요소가 필요하다.
1. 케라스(Keras)나 파이토치(PyTorch)
    - 텐서플로우를 백엔드로 사용하는 프런트엔드 프레임워크
    - 신경망을 쉽게 생성할 수 있게해주는 메서드를 모아 놓은 것
2. 생성기와 판별기: 두 가지 신경망 기반 구성 요소 

<p style="font-size: 1.12em">📌 GAN의 수행 방법</p>
- 생성기: 화폐 위조범 
- 판별기: FBI 요원

위조범은 FBI 요원의 검사를 통과할 수 있는 위조 지폐를 만드는 새로운 방법을 끊임없이 모색한다. 
이 두 구성요소의 목표를 세분화하면 다음과 같다.
- **위조범에 해당하는 생성기의 목표**: 경찰이 진짜 화폐와 가짜 화폐를 구별하지 못하도록 화폐 생성
- **경찰에 해당하는 판별기의 목표**: 진짜 화폐와 가짜 화폐을 분류해 나는 사전 경험을 바탕으로 예외적인 제품을 탐지

<p style="font-size: 1.12em">📌 GAN의 작동 방법</p>
GAN의 구현의 최소최대 문제(가장 큰 손실에서 함수를 최대화하는 데 중점을 둔 이론)이다. 이 단계들은 이러한 유형의 문제를 만들어낸다.
- **생성기의 목표**: 진짜 같은 가짜 출력을 생성해 내어 판별기가 실수로 진짜와 가짜를 잘못 분류하게 되는 가능성을 극대화
- **판별기의 목표**: 판별기가 진짜 이미지와 생성된 이미지를 구별하지 못할 확률 목표인 0.5를 달성하게 되기 전까지 최적화
- 최소최대 문제
    + GAN의 경우, 훈련하는 두 모델로 표현 가능
    + 훈련 단계에서 생성기에 대한 훈련 손실 오차를 최소화하는데 중점
    + 그 과정에서 판별기의 판별 확률은 가능한 0.5에 근접해져야한다.(판별기가 진짜인지 가짜인지 구분하기 힘들게)


GAN 모델은 적대적 훈련(`adversarial traing`)에 의존한다. 아래 그림을 보면 서로 상충되는 것으로 보이는 두 가지 오차 함수(`error functions`)가 각자 '최소화/최대화' 되고 있다. 
생성기가 출력해 낸 이미지는 분류에 성공할 확률을 낮추려고 하고, 판별기는 분류에 성공할 확률을 높이려고 한다. 이 때 서로가 서로를 경쟁적으로 발전시키는 구조가 되는 것이다.  따라서 생성기는 오차를 최대화, 판별기는 오차를 최소화하려고한다. 


GAN 프레임워크에서 생성기는 판별기와 동시에 훈련을 시작해야하지만, 실제로는 판별기가 이미지를 분류할 수 있어야하므로, 대체로 훈련을 시작하기 전에 판별기부터 훈련해야한다. 손실 함수(`loss function`)을 기준으로 삼아 생성기와 판별기를 훈련하는도중일지라도 훈련을 중단할 수 있다. 

<p align="center"><img src="/assets/images/gan20.png" width="60%" height="60%"></p>

위 그림은 생성적 적대 신경망의 흐름을 추상적으로 형태로 나타낸 그림으로, 각 사각형이 각 기본 함수를 의미한다. 생성기는 오차가 최대화 되도록, 판별기는 오차가 최소화 되도록 훈련한다. 

이 아키텍처를 사용해 각 부분을 구성요소 기술인 **생성기, 판별기 및 손실함수**로 분해해 살펴볼 차례이다. 또한 모델을 훈련하는 방법과 모델이 훈련한 뒤에 데이터를 획득하는 방법을 살펴보자. 

<br>

#### Generator
---

그림 중 강조 처리한 부분은 생성기 아키텍처를 이루는 주요 부분들이다. 생성기 부분에서 개발해야 할 코드 중에 핵심 부분이 무엇인지 알 수 있다. 

<p align="center"><img src="/assets/images/gan16.png" width="60%" height="60%"></p>    


- 생성기를 만드는 방법
1. 생성기: 잠재공간(`latent space`)에서 **표본(`samples`)을 추출**해 잠재 공간과 출력 간의 관계를 생성하는 역할
2. 입력(잠재공간)에서 출력(이미지)을 향해 가는 신경망 생성
3. 한 모델 안에서 생성기와 판별기를 서로 연결해 적대모드(`adversarial mode`)를 취해 생성기 훈련
4. 생성기의 훈련이 끝낸 뒤에 생성기를 추론에 사용 가능

각 빌딩 블록이 무척 도특하지만, 그 중에서 생성기는 반드시 이해해야 할 가장 중요한 개념이다. 
- 전체 훈련 과정이 완료된 후, 생성기는 표현하려고 하는 이미지(출력)를 생성함
- 생성기 훈련은 GAN 훈련에 직접적으로 관련되어 있음
- 훈련 과정에 착수하기 전에 판별기를 미리 훈련해 둬야함

각 부분에 관련된 코드의 구조를 이해해야한다. 생성기 클래스는 3가지 주요 함수가 필요하다.
- <mark>lossfunction()</mark>: **손실함수**, 모델을 훈련할 때 사용하는 사용자 정의 손실 함수를 정의함
- <mark>buildModel()</mark>: **모델 구축 함수**, 주어진 신경망의 실제 모델을 구성
- <mark>trainModel()</mark>

```python
class Generator:

    def __init__(self):
        self.initVariable = 1

    def lossFunction(self):
        return

    def buildModel(self):
        return

    def trainModel(self. inputX, inputY):
        return 
``` 


위 코드는 생성기 개발을 위한 클래스 템플릿이다. 여기에 소속된 각 함수는 각 생성기 클래스에 대해 구현해야하는 기본 구성 요소를 의미한다.     
모델을 훈련해 나가는 순서(`sequence`)가 이 클래스 안에 있을 것이다.


<br>

#### Discriminator
---

위 그림에서 강조 처리한 부분인 판별기 아키텍처는 이미지가 진짜인지 가짜인지 가려내는 역할이다. 판별기 역할을 담당할 신경망으로는 일반적으로 간단한 아키텍처로 이뤄진 **합성곱 신경망(`Convolution Neural Network, CNN`)**을 사용한다. 

<p align="center"><img src="/assets/images/gan17.png" width="60%" height="60%"></p>     


- 판별기 만드는 방법
1. 진짜와 가짜를 분류(이진 분류에 해당)하는 데 사용할 합성곱 신경망 생성
2. 진짜 데이터로만 구성된 데이터셋을 만들고, 생성기를 사용해 가짜 데이터로만 구성된 데이터셋도 만든다
3. 진짜 데이터와 가짜 데이터를 사용해 판별기 모델 훈련
4. 생성기를 훈련함으로써 훈련된 판별기와 서로 균형 잡는 방법을 학습(판별기가 너무 뛰어나면 생성기가 발산하게 된다는 점을 이용)
    + 생성기가 발산하게 되면, 판별자가 식별하기 어려울 만큼 잘 모방한 데이터를 생성하게 됨

이 판별기는 여러 판별기 모델의 장점을 모두 취할 수 있고, GAN 전체에 대한 적응 손실 함수(`adaptive loss function`)로 작용할 수 있다. 
- 즉, 이 판별기가 데이터의 **근원 분포(`underlying distribution`)**에 적응할 수 있다.
- GAN에서 생성기의 목표: 진짜 데이터의 분포에 대한 최대한 일치하는 데이터 분포를 지닌 가짜 데이터를 생성해 내는 것
- 진짜 데이터 분포를 완벽히 모방해 낼 수 가짜 데이터 분포를 생성기가 찾아내는 것이 핵심
- 이 분포를 바탕으로 가짜 데이터를 생성하는 것이 GAN의 궁극적인 목표
- 그러므로 **데이터 분포는 GAN의 핵심 개념이다**
- 현재의 딥러닝 모델이 오늘날 각광받는 이유
    + 과거에는 데이터의 근원 분포에 대한 계산을 자주 직접 해야했음
    + 오늘날 심층 신경망은 데이터 분포를 바탕으로 적응하고 학습할 수 있음 -> GAN 기법에서 이런 측면 활용

궁극적으로, 판별기는 진짜 이미지가 진짜인지 가짜인지, 그리고 생성된 이미지가 진짜인지 가짜인지를 평가(`evaluate`)할 것이다.
- 초기: 진짜 이미지의 척도(`scale`)가 가르키는 점수를 높임, 생성된 이미지인 경우 척도가 가르키는 점수를 낮춤
    + 척도: GAN의 유용성을 나타내는 계랑기준(`metric`)
    + 진짜인지 가짜인지를 척도를 기준으로 보았을 때, 진짜라면 점수가 높고 가짜라면 점수가 낮을 것
- 점차적으로 판별기는 생성된 이미지와 진짜 이미지를 구분하는데 어려움을 겪을 것
    + 생성기가 점점 더 진짜에 가까운 이미지를 생성할 것이기 때문
- 판별기는 모델을 구축하는 일에 의존하게 될것이고, 잠재적으로는 초기 손실 함수에 의존할 것이다.

```python
class Discriminator:

    def __init__(self):
        self.initVariable = 1

    def lossFunction(self):
        return

    def buildModel(self):
        return

    def trainModel(self. inputX, inputY):
        return 
``` 

위 코드는 판별기 개발을 위한 클래스 템플릿이다. 각 판별기 클래스에 구현해야하는 기본 구성요소를 나타낸다.

<br>

#### Loss Function
---
각 신경망을 훈련하는 데 필요한 어떤 **구조 요소(`structural components`)** 같은 게 있다. 신경망에서는 주어진 문제 집합에 대한 훈련 과정 중에서 가중치를 조절함으로써 손실 함수가 최적화되게 한다. 
즉, 손실 함수를 metrics으로 삼아 신경망을 적합시켜 나간다. 신경망이 좋은 결과를 산출하면서 수렴하도록 하려면 신경망에 알맞은 **손실 함수(`loss functions`)**를 선택하는 일이 중요하다. 

생성기에 맞는 손실 함수를 적절하게 선택함으로써(신경망을 사용하는 목적에 맞게 손실함수를 선택함으로써) 신경망이 수렴할 수 있게 해야한다. 서로 다른 손실 함수를 사용할 떄 마다 서로 다른 결과를 얻게 된다.

<p style="font-size: 1.12em">📌 생성기용 손실 함수</p>
<p align="center"><img src="/assets/images/gan18.png" width="35%" height="35%"></p>

굿펠로우와 그의 동료들이 사용한 손실함수로 초기 GAN 논문에 나오는 손실 함수이다. 적대적 훈련을 할 때 생성기에서 사용하는 손실 함수이다.

- 이 방정식은 판별기가 옳게 판단을 했는지를 나타내는 로그 확률을 판별기가 줄여 나가고 있다. 
- 이 방정식은 벌어지고 있는 적대 훈련 모드 중 일부를 보여줄 뿐 이다.
- 이와 관련해서 생성기의 손실 함수가 문제가 된다는 점을 고려해야한다. 
    + **경사도 포화(`gradient saturation`)**: 경사도들(학습 성공 여부를 의미)이 0이 가까워서 학습을 거의 불가능하게 할 때 발생하는 문제
    + 손실 함수를 잘못 설계해서 발생하는 문제
    + 적절한 손실 함수를 선택하는 일이 중요

<p style="font-size: 1.12em">📌 판별기용 손실 함수</p>
<p align="center"><img src="/assets/images/gan19.png" width="60%" height="60%"></p>

굿펠로우의 논문에 나오는 손실함수이다. GAN에 적용되는 표준 교차 엔트로피 구현한 방정식이다.

- 표준 교차 엔트로피(`standard cross-entropy`)를 구현한 것
- 이 방정식에 보이는 독특한 점: **미니배치(`mini-batches`)**가 여러 개일 때 훈련되는 방식
    + 미니 배치: 훈련 데이터를 분할해 만든 작은 데이터 집단(batch)


GAN을 이루는 전체 아키텍처에 대해서 판별기는 **'학습된 손실함수'**인 것처럼 등장한다. 하지만 생성기나 판별기와 같은 각 모델이 서로 짝을 이루게 되는 GAN 아키텍처에서는, 각 부분적 모델을 구축할 때도 여려 가지 손실 함수가 필요하다. 이런 경우를 대비해 손실 함수용 템플릿 클래스를 정의해 두자

```python
class Loss:
    def __init__(self):
        self.initVariable = 1

    def lossBaseFunction1(self):
        return

    def lossBaseFunction2(self):
        return

    def lossBaseFunction3(self):
        return
```

사용할 손실 함수가 무엇인가에 따라 선택적으로 구현되는 손실 함수의 클래스 템플릿이다. 




<!-- ![Image Alt 텍스트](https://post-phinf.pstatic.net/MjAxODA4MDJfMTU5/MDAxNTMzMTg1NjIyODk0.PQRCts3UHTjC2Y3YZInqHaSVYKNzKyASqLaSqo2j3BEg.a4qXJ8U7i-7wNec_irjGVlY9cuZSb2S68Dif80JVykAg.PNG/4GAN%ED%95%99%EC%8A%B5%EA%B3%BC%EC%A0%95_%EC%88%98%EC%A0%952.PNG?type=w1200){: width="70%" height="70%"} 

---

<p style="font-size: 1.0em">References</p>
<a href = "https://post.naver.com/viewer/postView.nhn?volumeNo=16425037&memberNo=36733075&vType=VERTICAL" style="font-size: 0.8em"> [새로운 인공지능 기술 GAN] ① 스스로 학습하는 인공지능 </a>      
<a href = "https://m.post.naver.com/viewer/postView.nhn?volumeNo=16566740&memberNo=36733075" style="font-size: 0.8em"> [새로운 인공지능 기술 GAN] ② GAN의 개념과 이해</a>       
<a href = "https://post.naver.com/viewer/postView.nhn?volumeNo=16706734&memberNo=36733075" style="font-size: 0.8em"> [새로운 인공지능 기술 GAN] ③ GAN의 활용 사례와 발전방향</a> -->