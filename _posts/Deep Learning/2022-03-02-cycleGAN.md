---
layout: post
title: "[GAN] CycleGAN"
date: 2020-11-05 08:44:38 -0400
category: deep-learning
author: eun
short-description: CycleGAN
toc: true
use_math: true
---

#### intro
---

CycleGAN은, 한 이미지의 특성을 캡처하고 그 특징을 다른 이미지에 쉽게 입힐 수 있는 모델이다.

<p align="center"><img src="/assets/images/cyclegan_02.PNG"  width="50%" height="50%"></p>

CycleGAN을 사용하면 말 사진에, 얼룩말의 특성을 씌워서 말 이미지를 얼룩말 이미지로 만들 수 있다. 이 뿐만 아니라, 여름 사진을 겨울 사진으로, 기본 사진을 아웃오브 포커스 사진으로, 얼굴을 라면으로 등 다양한 작업을 할 수 있다. 

<br>

#### CycleGAN
---


<p align="center"><img src="/assets/images/cyclegan_03.PNG"  width="50%" height="50%"></p>

pix2pix와 다르게, **짝(`pair`)을 이루는 입출력 데이터가 필요하지 않다.** (비지도학습) 
화풍 모사의 많은 애플리케이션에서 짝 데이터(`paired data`)는 훈련에 필수적인 부분이다.

CycleGAN은 과거의 틀을 깨고 나와 짝 입력이 없는 모델을 안정적으로 훈련할 수 있던 최초의 GAN 구현 중 하나이다.

즉, 훈련 데이터로써 각각이 짝이 되지 않은 두 개의 이미지 군집을 전달해 말 → 얼룩말, 여름 사진 → 겨울 사진이라는 사진의 이미지를 학습한다. 그 후 한 쪽 이미지가 다른 쪽의 이미지로 자동적으로 변환되도록 하는 것이다.


CycleGAN에서 생성기와 판별기로 아주 간단한 합성곱 신경망들(`convolutional neural network, CNNs`)을 사용한다. 이 논문의 비밀의 원천은 아키텍처를 구현한 방식에 있다.**A → B, B → A**, 이 표현(`representation`)을 학습할 수 있게 훈련하기 위해  이 신경망들을 봉합(`stitch`)한 방식인 셈이다.

<p style="font-size: 1.12em">[CycleGAN's pseudocode]</p>

```python
1.  A → B, B → A로 향하는 생성기 초기화 

    #논문을 바탕으로 모델 구축
    init generator_A_to_B
    init generator_B_to_A

2. 각 이미지 유형(각 화풍마다 하나씩)에 대한 판별기 초기화

    init discriminatorA
    init discriminatorB

3. 모든 신경망을 적대적인 훈련 아키텍처에 맞게 구성하고 신경망을 초기화, 훈련

    init GAN()

4. A와 B의 배치들을 부여잡은채로 각 판별기 훈련, GAN 모델을 적대 모드로 훈련해 신경망을 훈련

    while 배치가 아직 남아 있는 동안:
        grab BatchA # A 배치 부여잡읍(확득함)
        grab BatchB # B 배치 부여잡읍(확득함)

        train discriminatorA(BatchA) # A 배치를 사용해 A 판별기 훈련
        train discriminatorB(BatchB) # B 배치를 사용해 B 판별기 훈련

        train GAN(BatchA, BatchB) # A 배치와 B 배치로 GAN 훈련     
```

수도코드는 간단하지만 이것을 부기해(`bookeeping`)두는 일에 주의를 기울여야한다.(많은 생성기를 갖게 될 것)

<br>

#### Architecture
---

논문은 CycleGAN 학습 방법을 다음과 같은 설명했다.
1. 이미지 군집의 특징 추출
2. 특징이 다른 이미지군을 어떻게 변화시킬 수 있는가 이해

전반적인 설계는 3가지 단계로 구성된다.
1.  서로 다른 두 가지 화풍 간 변환(`translate`)할 수 있으려면 **두 개의 생성기와 두 개의 판별기**가 필요하다. 
    - **생성기 G**는 X에서 Y로 변환, **판별기 Y(DY)**에 의해 검사
    - **생성기 F**는 Y에서 X로 변환, **판별기 Y(DX)**에 의해 검사
    - 반대 도메인을 위한 판별자를 속이기 위해 학습, GAN의 손실함수를 더 진짜 같이 만드는 과정
    <p align="center"><img src="/assets/images/cyclegan_04.png"  width="30%" height="30%"></p>

    - ex)
    - G는 조랑말 X 이미지를 얼룩말 Y로 변환한다. F는 얼룩말 Y 이미지를 조랑말 X 이미지로 변환한다.
    - G(X)는 X를 G로 통해 이미지를 변환하고 도메인 Y를 가진다. F(X)는 Y를 F로 통해 이미지를 변환하고 도메인 X를 가진다.
    - $D_X$, $D_Y$는 판별기다.
2. $x$에서$\hat y$로 평가(`evaluate`)해 본 후에 $\hat x$를 재구성한다. 
    - 재구성된 $\hat x$로 돌아감으로써 학습기의 기초가 되는 확실한 계량기준(`metric`)을 얻을 수 있다.
    <p align="center"><img src="/assets/images/cyclegan_05.PNG"  width="30%" height="30%"></p>
3. $y$에서 $\hat x$로 화풍을 모사한 다음 $\hat y$을 재구성한다.
    - 양쪽 방향으로 이와 같은 일을 진행함으로써 변환된 사진과 재구성한 사진을 적대적인 단계로 평가할 수 있는 아키텍처 정의
    <p align="center"><img src="/assets/images/cyclegan_06.png"  width="30%" height="30%"></p>



---
---
<p style="font-size: 1.0em">References</p>

<a href = "https://github.com/wikibook/gan" style="font-size: 0.8em"> 실전 예제로 배우는 GAN(위키북스) </a>      
<a href = "https://arxiv.org/pdf/1703.10593.pdf" style="font-size: 0.8em"> Unpaired Image-to-Image Translation
using Cycle-Consistent Adversarial Networks </a>      
